import streamlit as st
from PIL import Image
from openai import OpenAI
import json
import os

# ---------------------------
# 1. í˜ì´ì§€ ì„¤ì •
# ---------------------------
st.set_page_config(
    page_title="ì—¬í–‰ ì—°êµ¬ ì±—ë´‡",
    page_icon="âœˆï¸",  # ë”°ì˜´í‘œ ì˜¤ë¥˜ ìˆ˜ì • ì™„ë£Œ
    layout="wide"
)

# ---------------------------
# 2. API ë° ë°ì´í„° ë¡œë“œ
# ---------------------------
try:
    api_key = st.secrets["OPENAI_API_KEY"]
except FileNotFoundError:
    st.error("ë¹„ë°€ í‚¤ íŒŒì¼(.streamlit/secrets.toml)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

client = OpenAI(api_key=api_key)

@st.cache_data
def load_data():
    try:
        with open('travel_data.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return []

travel_db = load_data()

# ---------------------------
# 3. ì‹¤í—˜ ì¡°ê±´ ì œì–´ (URL íŒŒë¼ë¯¸í„°)
# ---------------------------
query_params = st.query_params
group_id = query_params.get("group", "researcher")

# [ê¸°ë³¸ê°’ ì„¤ì •]
use_ontology = True         # True: ë°ì´í„° ì‚¬ìš© / False: ì¼ë°˜ ChatGPT
data_filter = "All"         # All, High, Low
interaction = "Response"    # Response, Clarifying
hide_sidebar = False        # ì°¸ê°€ì ëª¨ë“œ ì—¬ë¶€

# [ê·¸ë£¹ë³„ ì¡°ê±´ ë§¤í•‘]
# Study 1: ë§¤ì²´ ë¹„êµ
if group_id == "S1_Basic":
    use_ontology = False
    hide_sidebar = True
elif group_id == "S1_Ontology":
    use_ontology = True
    data_filter = "All"
    interaction = "Response"
    hide_sidebar = True

# Study 2: ì •ë³´ ì†ì„± ë¹„êµ
elif group_id == "S2_Pop":
    use_ontology = True
    data_filter = "High"
    interaction = "Response"
    hide_sidebar = True
elif group_id == "S2_Seren":
    use_ontology = True
    data_filter = "Low"
    interaction = "Response"
    hide_sidebar = True

# Study 3: ìƒí˜¸ì‘ìš© ë¹„êµ (2x2)
elif group_id == "S3_Pop_Resp":
    use_ontology = True
    data_filter = "High"
    interaction = "Response"
    hide_sidebar = True
elif group_id == "S3_Pop_Clar":
    use_ontology = True
    data_filter = "High"
    interaction = "Clarifying"
    hide_sidebar = True
elif group_id == "S3_Seren_Resp":
    use_ontology = True
    data_filter = "Low"
    interaction = "Response"
    hide_sidebar = True
elif group_id == "S3_Seren_Clar":
    use_ontology = True
    data_filter = "Low"
    interaction = "Clarifying"
    hide_sidebar = True

# ---------------------------
# 4. í™”ë©´ êµ¬ì„± (ë¡œê³  ë° ì‚¬ì´ë“œë°”)
# ---------------------------

# [ì—°êµ¬ì ëª¨ë“œ] ì‚¬ì´ë“œë°”ì— ë¡œê³  ë° íŒ¨ë„ í‘œì‹œ
if not hide_sidebar:
    with st.sidebar:
        try:
            img = Image.open("Fitlab.png")
            st.image(img, caption="Fitlab", use_container_width=True)
        except:
            st.warning("ë¡œê³  íŒŒì¼(Fitlab.png) ì—†ìŒ")
        
        st.header("ğŸ”¬ ì—°êµ¬ììš© ì„¤ì •")
        use_ontology = st.checkbox("ì˜¨í†¨ë¡œì§€ ë°ì´í„° ì‚¬ìš©", value=True)
        data_filter = st.radio("ì •ë³´ ì†ì„±", ["All", "High (Popularity)", "Low (Serendipity)"])
        interaction = st.radio("ìƒí˜¸ì‘ìš©", ["Response (ìˆ˜ë™)", "Clarifying (ì—­ì§ˆë¬¸)"])
        
        if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state['messages'] = []
            st.rerun()

# [ì°¸ê°€ì ëª¨ë“œ] ì‚¬ì´ë“œë°” ìˆ¨ê¸°ê³ , ë©”ì¸ í™”ë©´ ìƒë‹¨ì— ë¡œê³  í‘œì‹œ
if hide_sidebar:
    # ì‚¬ì´ë“œë°” ìˆ¨ê¹€ CSS
    st.markdown("""<style>[data-testid="stSidebar"] {display: none;}</style>""", unsafe_allow_html=True)
    
    # ë©”ì¸ ìƒë‹¨ ë¡œê³  í‘œì‹œ
    try:
        col1, col2 = st.columns([1, 9])
        with col1:
            img = Image.open("Fitlab.png")
            st.image(img, use_container_width=True)
    except:
        pass

# ---------------------------
# 5. ë„ì‹œ ì„ íƒ ë° ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
# ---------------------------
if "selected_city" not in st.session_state:
    st.session_state["selected_city"] = None

st.title("âœˆï¸ ë‚˜ë§Œì˜ ì—¬í–‰ ê³µë™ ìƒì‚°ì")

# [STEP 1] ë„ì‹œ ì„ íƒ í™”ë©´
if st.session_state["selected_city"] is None:
    st.subheader("ë– ë‚˜ê³  ì‹¶ì€ ì—¬í–‰ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”")
    # LAë¥¼ ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤ë¡œ ìˆ˜ì •
    cities = ["ë„ì¿„", "íŒŒë¦¬", "ë¼ìŠ¤ë² ê±°ìŠ¤", "ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤", "ì‹œë“œë‹ˆ", "ë² ì´ì§•", "ë‰´ìš•"]
    cols = st.columns(4)
    for i, city in enumerate(cities):
        if cols[i % 4].button(city, use_container_width=True):
            st.session_state["selected_city"] = city
            st.session_state["messages"] = []
            st.rerun()

# [STEP 2] ì±„íŒ… í™”ë©´
else:
    # ìƒë‹¨ ë„ì‹œ í‘œì‹œ ë° ë³€ê²½ ë²„íŠ¼
    c1, c2 = st.columns([8,2])
    c1.success(f"ì„ íƒëœ ë„ì‹œ: **{st.session_state['selected_city']}**")
    if c2.button("ë„ì‹œ ë³€ê²½"):
        st.session_state["selected_city"] = None
        st.rerun()

    selected_city = st.session_state['selected_city']

    # --- í”„ë¡¬í”„íŠ¸ ì¡°ë¦½ (í’ë¶€í•œ ì„¤ëª… + ì¡°ê±´ ë°˜ì˜) ---
    
    # 1. ì¼ë°˜ LLM (Study 1 ëŒ€ì¡°êµ°)
    if not use_ontology:
        system_prompt = f"""
        ë„ˆëŠ” '{selected_city}' ì—¬í–‰ ê°€ì´ë“œì•¼. 
        ì¼ë°˜ì ì¸ ì¸í„°ë„· ì •ë³´(ChatGPT ì§€ì‹)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œí•´ì¤˜.
        ì¹œêµ¬ì²˜ëŸ¼ í¸ì•ˆí•˜ê²Œ ë°˜ë§ë¡œ ëŒ€ë‹µí•´ì¤˜.
        """
    
    # 2. ì˜¨í†¨ë¡œì§€ ìµœì í™” LLM (Study 1, 2, 3)
    else:
        # ë°ì´í„° í•„í„°ë§
        city_data = [d for d in travel_db if d['city'] == selected_city]
        
        if "High" in data_filter:
            final_data = [d for d in city_data if d['popularity'] == "High"]
        elif "Low" in data_filter:
            final_data = [d for d in city_data if d['popularity'] == "Low"]
        else:
            final_data = city_data # All

        # [ìˆ˜ì •ë¨] í’ë¶€í•œ ì„¤ëª…ì„ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸
        system_prompt = f"""
        ë„ˆëŠ” '{selected_city}' ì—¬í–‰ ìµœì í™” AIì•¼.
        
        [í•µì‹¬ ì§€ì¹¨]
        1. **ì¥ì†Œ ì„ ì •:** ë°˜ë“œì‹œ ì•„ë˜ [ì œê³µëœ ë°ì´í„°] ëª©ë¡ì— ìˆëŠ” ì¥ì†Œë“¤ ì¤‘ì—ì„œë§Œ ê³¨ë¼ì„œ ì¶”ì²œí•´.
        2. **ì„¤ëª… ë°©ì‹:** [ì œê³µëœ ë°ì´í„°]ì˜ ì •ë³´ë¥¼ ë¼ˆëŒ€ë¡œ í•˜ë˜, **ë„¤ê°€ ì›ë˜ ì•Œê³  ìˆëŠ” ì§€ì‹(ì—­ì‚¬, ê¿€íŒ, ë§›ì§‘ ë“±)ì„ ì‚´ì„ ë¶™ì—¬ì„œ ì•„ì£¼ í’ì„±í•˜ê²Œ** ì„¤ëª…í•´ì¤˜. ë‹¨ë‹µí˜• ê¸ˆì§€.
        3. ë§íˆ¬ëŠ” ì¹œêµ¬ì²˜ëŸ¼ ì¹œê·¼í•œ ë°˜ë§ë¡œ í•´ì¤˜.
        
        [ì œê³µëœ ë°ì´í„°]
        {json.dumps(final_data, ensure_ascii=False)}
        """

        # ìƒí˜¸ì‘ìš© ì¡°ê±´ (Study 3)
        if interaction == "Clarifying" or interaction == "Clarifying (ì—­ì§ˆë¬¸)":
            system_prompt += """
            [ëŒ€í™” ìŠ¤íƒ€ì¼: ì—­ì§ˆë¬¸ ëª¨ë“œ]
            1. ì‚¬ìš©ìì˜ ì²« ì§ˆë¬¸ì— ë°”ë¡œ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì£¼ì§€ ë§ˆ.
            2. ë°˜ë“œì‹œ "ëˆ„êµ¬ë‘ ê°€?", "ì–´ë–¤ ë¶„ìœ„ê¸° ì¢‹ì•„í•´?" ê°™ì€ **ì—­ì§ˆë¬¸(Clarifying Question)ì„ 2~3ê°œ** ë¨¼ì € ë˜ì ¸ì„œ êµ¬ì²´ì ì¸ ìƒí™©ì„ íŒŒì•…í•´.
            3. ì‚¬ìš©ìê°€ ëŒ€ë‹µí•˜ë©´, "ë„¤ ìƒí™©ì„ ë³´ë‹ˆ ì—¬ê¸°ê°€ ë”±ì´ì•¼!"ë¼ë©° **ê³µë™ ìƒì‚°(Co-creation)**í•˜ëŠ” ëŠë‚Œìœ¼ë¡œ ì¶”ì²œí•´.
            """
        else:
            system_prompt += """
            [ëŒ€í™” ìŠ¤íƒ€ì¼: ìˆ˜ë™ ì‘ë‹µ ëª¨ë“œ]
            1. ì‚¬ìš©ìê°€ ë¬¼ì–´ë³´ë©´ ëœ¸ ë“¤ì´ì§€ ë§ê³  ì¦‰ì‹œ ì¶”ì²œ ì¥ì†Œë¥¼ ì•Œë ¤ì¤˜.
            2. ë˜ë¬»ê±°ë‚˜(Questioning) ëŒ€í™”ë¥¼ ê¸¸ê²Œ ëŒì§€ ë§ê³ , ìš”ì²­í•œ ì •ë³´ë¥¼ ì‹œì›ì‹œì›í•˜ê²Œ ì „ë‹¬í•´.
            """

    # --- ë©”ì‹œì§€ ê´€ë¦¬ ---
    if "messages" not in st.session_state or len(st.session_state["messages"]) == 0:
        st.session_state["messages"] = [{"role": "system", "content": system_prompt}]
    else:
        # ì¡°ê±´ ë³€ê²½ ì‹œ í”„ë¡¬í”„íŠ¸ ê°±ì‹ 
        st.session_state["messages"][0] = {"role": "system", "content": system_prompt}

    # --- ì±„íŒ… UI ì¶œë ¥ ---
    for msg in st.session_state.messages:
        if msg["role"] != "system":
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

    # --- ì‚¬ìš©ì ì…ë ¥ ---
    if prompt := st.chat_input("ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!"):
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=st.session_state.messages
            )
            bot_reply = response.choices[0].message.content
            st.chat_message("assistant").markdown(bot_reply)
            st.session_state.messages.append({"role": "assistant", "content": bot_reply})
        except Exception as e:
            st.error(f"Error: {e}")