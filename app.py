import streamlit as st
from PIL import Image
from openai import OpenAI
import json
import os

# ---------------------------
# 1. í˜ì´ì§€ ì„¤ì •
# ---------------------------
st.set_page_config(
    page_title="ì—¬í–‰ ì±—ë´‡",
    page_icon="âœˆï¸",
    layout="wide"
)

# ---------------------------
# 2. API ë° ë°ì´í„° ë¡œë“œ
# ---------------------------
try:
    api_key = st.secrets["OPENAI_API_KEY"]
except FileNotFoundError:
    st.error("ë¹„ë°€ í‚¤ íŒŒì¼(.streamlit/secrets.toml)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

client = OpenAI(api_key=api_key)

@st.cache_data
def load_data():
    try:
        with open('travel_data.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return []

travel_db = load_data()

# ---------------------------
# 3. ì‹¤í—˜ ì¡°ê±´ ì œì–´ (í•µì‹¬ ë¡œì§)
# ---------------------------
# URL íŒŒë¼ë¯¸í„° ì½ê¸°
query_params = st.query_params
group_id = query_params.get("group", "researcher")

# [ê¸°ë³¸ê°’ ì„¤ì •]
use_ontology = True         # True: ì—¬í–‰ ë°ì´í„° ì‚¬ìš© / False: ì¼ë°˜ ChatGPT (Study 1 ëŒ€ì¡°êµ°)
data_filter = "All"         # All, High(Popularity), Low(Serendipity)
interaction = "Response"    # Response(ìˆ˜ë™), Clarifying(ì—­ì§ˆë¬¸)
hide_sidebar = False        # ì°¸ê°€ìì—ê²Œ ì‚¬ì´ë“œë°” ìˆ¨ê¹€ ì—¬ë¶€

# ---------------------------------------------------------
# [ì¤‘ìš”] ê·¸ë£¹ë³„ ì¡°ê±´ ë§¤í•‘ (ì„ ìƒë‹˜ì´ ìš”ì²­í•œ ëª¨ë“  ì¡°ê±´)
# ---------------------------------------------------------

# --- Study 1: ë§¤ì²´ ë¹„êµ (ì¼ë°˜ LLM vs Ontology LLM) ---
if group_id == "S1_Basic":
    # ì¼ë°˜ ChatGPT (ë°ì´í„° ì•ˆ ì”€)
    use_ontology = False
    hide_sidebar = True

elif group_id == "S1_Ontology":
    # ì—¬í–‰ ìµœì í™” LLM (ë°ì´í„° ì‚¬ìš©, êµ¬ì¡°ì  ë‹µë³€)
    use_ontology = True
    data_filter = "All" 
    interaction = "Response"
    hide_sidebar = True

# --- Study 2: ì •ë³´ ì†ì„± ë¹„êµ (Popularity vs Serendipity) ---
elif group_id == "S2_Pop":
    use_ontology = True
    data_filter = "High" # Popularity
    interaction = "Response"
    hide_sidebar = True

elif group_id == "S2_Seren":
    use_ontology = True
    data_filter = "Low"  # Serendipity
    interaction = "Response"
    hide_sidebar = True

# --- Study 3: 2x2 ìƒí˜¸ì‘ìš© ë¹„êµ (Pop/Seren x Resp/Clar) ---
elif group_id == "S3_Pop_Resp":
    use_ontology = True
    data_filter = "High"
    interaction = "Response"
    hide_sidebar = True

elif group_id == "S3_Pop_Clar":
    use_ontology = True
    data_filter = "High"
    interaction = "Clarifying"
    hide_sidebar = True

elif group_id == "S3_Seren_Resp":
    use_ontology = True
    data_filter = "Low"
    interaction = "Response"
    hide_sidebar = True

elif group_id == "S3_Seren_Clar":
    use_ontology = True
    data_filter = "Low"
    interaction = "Clarifying"
    hide_sidebar = True

# ---------------------------------------------------------

# [ì—°êµ¬ììš© ìˆ˜ë™ íŒ¨ë„] (URLì— group ì—†ìœ¼ë©´ ë³´ì„)
if not hide_sidebar:
    with st.sidebar:
        try:
            img = Image.open("Fitlab.png")
            st.image(img, caption="Fitlab", use_container_width=True)
        except:
            st.write("Fitlab")
        
        st.header("ğŸ”¬ ì—°êµ¬ììš© ì„¤ì •")
        use_ontology = st.checkbox("ì˜¨í†¨ë¡œì§€ ë°ì´í„° ì‚¬ìš©", value=True)
        data_filter = st.radio("ì •ë³´ ì†ì„±", ["All", "High (Popularity)", "Low (Serendipity)"])
        interaction = st.radio("ìƒí˜¸ì‘ìš©", ["Response (ìˆ˜ë™)", "Clarifying (ì—­ì§ˆë¬¸)"])
        
        if st.button("ì´ˆê¸°í™”"):
            st.session_state['messages'] = []
            st.rerun()

if hide_sidebar:
    st.markdown("""<style>[data-testid="stSidebar"] {display: none;}</style>""", unsafe_allow_html=True)


# ---------------------------
# 4. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
# ---------------------------
if "selected_city" not in st.session_state:
    st.session_state["selected_city"] = None

st.title("âœˆï¸ ì—¬í–‰ íŒŒíŠ¸ë„ˆ AI")

# [STEP 1] ë„ì‹œ ì„ íƒ
if st.session_state["selected_city"] is None:
    st.subheader("ì—¬í–‰ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”")
    cities = ["ë„ì¿„", "íŒŒë¦¬", "ë¼ìŠ¤ë² ê±°ìŠ¤", "ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤", "ì‹œë“œë‹ˆ", "ë² ì´ì§•", "ë‰´ìš•"]
    cols = st.columns(4)
    for i, city in enumerate(cities):
        if cols[i % 4].button(city, use_container_width=True):
            st.session_state["selected_city"] = city
            st.session_state["messages"] = []
            st.rerun()

# [STEP 2] ì±„íŒ… í™”ë©´
else:
    # ìƒë‹¨ ë„ì‹œ í‘œì‹œ
    c1, c2 = st.columns([8,2])
    c1.success(f"ì„ íƒëœ ë„ì‹œ: **{st.session_state['selected_city']}**")
    if c2.button("ë„ì‹œ ë³€ê²½"):
        st.session_state["selected_city"] = None
        st.rerun()

    selected_city = st.session_state['selected_city']

    # --- í”„ë¡¬í”„íŠ¸ ì¡°ë¦½ ì‹œì‘ ---
    
    # 1. ì¼ë°˜ LLM ëª¨ë“œ (Study 1 ëŒ€ì¡°êµ°)
    if not use_ontology:
        system_prompt = f"""
        ë„ˆëŠ” '{selected_city}' ì—¬í–‰ ê°€ì´ë“œì•¼. 
        ì¼ë°˜ì ì¸ ì¸í„°ë„· ì •ë³´(ChatGPT ì§€ì‹)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œí•´ì¤˜.
        ì¹œêµ¬ì²˜ëŸ¼ í¸ì•ˆí•˜ê²Œ ë°˜ë§ë¡œ ëŒ€ë‹µí•´ì¤˜.
        """
    
    # 2. ì˜¨í†¨ë¡œì§€ ìµœì í™” LLM ëª¨ë“œ (Study 1, 2, 3)
    else:
        # ë°ì´í„° í•„í„°ë§
        city_data = [d for d in travel_db if d['city'] == selected_city]
        
        if data_filter == "High (Popularity)" or data_filter == "High":
            final_data = [d for d in city_data if d['popularity'] == "High"]
        elif data_filter == "Low (Serendipity)" or data_filter == "Low":
            final_data = [d for d in city_data if d['popularity'] == "Low"]
        else:
            final_data = city_data # All

        # í”„ë¡¬í”„íŠ¸
        system_prompt = f"""
        ë„ˆëŠ” '{selected_city}' ì—¬í–‰ ìµœì í™” AIì•¼.
        ë°˜ë“œì‹œ ì•„ë˜ [ì œê³µëœ ë°ì´í„°]ì— ìˆëŠ” ì¥ì†Œë§Œ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì²œí•´ì¤˜.
        ì™¸ë¶€ ì§€ì‹ë³´ë‹¤ ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•´.
        
        [ì œê³µëœ ë°ì´í„°]
        {json.dumps(final_data, ensure_ascii=False)}
        """

        # ìƒí˜¸ì‘ìš© ì¡°ê±´ (Response vs Clarifying)
        if interaction == "Clarifying" or interaction == "Clarifying (ì—­ì§ˆë¬¸)":
            system_prompt += """
            [ì§€ì¹¨: ì—­ì§ˆë¬¸ ëª¨ë“œ]
            1. ì‚¬ìš©ìì˜ ì²« ì§ˆë¬¸ì— ë°”ë¡œ ì¥ì†Œë¥¼ ë‚˜ì—´í•˜ì§€ ë§ˆ.
            2. ë°˜ë“œì‹œ "ëˆ„êµ¬ë‘ ê°€?", "ì–´ë–¤ ë¶„ìœ„ê¸° ì¢‹ì•„í•´?" ê°™ì€ **ì—­ì§ˆë¬¸(Clarifying Question)ì„ 3ê°œ** ë¨¼ì € í•´.
            3. ì‚¬ìš©ìê°€ ëŒ€ë‹µí•˜ë©´ "ë„¤ ì·¨í–¥ì„ ë°˜ì˜í•´ì„œ ìš°ë¦¬ê°€ í•¨ê»˜ ì°¾ì€ ê³³ì€..." ì²˜ëŸ¼ **ê³µë™ ìƒì‚°(Co-creation)** ëŠë‚Œìœ¼ë¡œ ì¶”ì²œí•´ì¤˜.
            """
        else:
            system_prompt += """
            [ì§€ì¹¨: ìˆ˜ë™ ì‘ë‹µ ëª¨ë“œ]
            1. ì‚¬ìš©ìê°€ ë¬¼ì–´ë³´ë©´ ì¦‰ì‹œ ì •ë³´ë¥¼ ì œê³µí•´.
            2. ë˜ë¬»ê±°ë‚˜ ëŒ€í™”ë¥¼ ê¸¸ê²Œ ëŒì§€ ë§ê³ , ê¹”ë”í•˜ê²Œ ì •ë³´ë§Œ ì „ë‹¬í•´.
            """

    # --- ë©”ì‹œì§€ ê´€ë¦¬ ---
    if "messages" not in st.session_state or len(st.session_state["messages"]) == 0:
        st.session_state["messages"] = [{"role": "system", "content": system_prompt}]
    else:
        st.session_state["messages"][0] = {"role": "system", "content": system_prompt}

    # UI ì¶œë ¥
    for msg in st.session_state.messages:
        if msg["role"] != "system":
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

    if prompt := st.chat_input("ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!"):
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=st.session_state.messages
            )
            bot_reply = response.choices[0].message.content
            st.chat_message("assistant").markdown(bot_reply)
            st.session_state.messages.append({"role": "assistant", "content": bot_reply})
        except Exception as e:
            st.error(f"Error: {e}")